# ========================= docx_utils.py (Universal, auto-mapping) =========================
# TRF tick OK, SAMPLE PICTURE 3x4in (center), Summary & Detail auto-fill,
# Result style preserved. Supports ALL templates via TEMPLATE_MAP + TEST_GROUP_TITLES
# ===========================================================================================

import os
import re
import time
import uuid
import tempfile
import unicodedata
from io import BytesIO
import unicodedata

from openpyxl import load_workbook
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_ALIGN_VERTICAL
from datetime import datetime
from config import local_main, TEMPLATE_MAP
from test_logic import TEST_GROUP_TITLES
from excel_utils import _find_report_col

# Optional pandas dependency for cover fill from Excel
try:
    import pandas as pd
except Exception:
    pd = None

WORD_TEMPLATE = "FORM-QAD-011-TEST REQUEST FORM (TRF).docx"
PDF_OUTPUT_FOLDER = os.path.join("static", "TFR")
BLANK_TOKENS = {"", "-", "—", "–"}
_IMG_EXTS = (".png", ".jpg", ".jpeg", ".webp", ".bmp")

__all__ = [
    "get_first_empty_report_all_blank",
    "fill_docx_and_export_pdf",
    "approve_request_fill_docx_pdf",
    "fill_bed_cover_from_excel",
    "fill_cover_from_excel_generic",
    "create_report_for_type",
]

# ============================ Common helpers ============================

def _normalize_to_check_blank(v):
    if v is None:
        return True, ""
    if isinstance(v, str):
        s = (
            v.replace("\u00A0", "")
             .replace("\u200B", "")
             .replace("\r", "")
             .replace("\n", "")
             .replace("\t", "")
             .strip()
        )
        return (s in BLANK_TOKENS), s
    return False, str(v)

def remove_diacritics(s: str) -> str:
    """Loại bỏ dấu tiếng Việt để in ra file Word (Generated by)."""
    s = unicodedata.normalize("NFD", str(s or ""))
    return "".join(ch for ch in s if unicodedata.category(ch) != "Mn")

def _fill_generated_by_fields(doc: Document, generated_by: str | None) -> bool:
    """
    Điền tên người xuất report vào:
      1) Cover table: label 'Generated by:' → ô kế bên
      2) Signature block: hàng header 'Tested by | Generated by | Reviewed by' → hàng tên ở dưới (cột 'Generated by')
    - Bỏ dấu nếu tên có dấu
    - Không ghi nếu không có tên
    - Chỉ ghi nếu ô hiện đang là '-' hoặc trống
    """
    if not generated_by:
        return False
    name = generated_by or ""
    if "-" in name:
        name = name.split("-", 1)[1].strip()
    name = remove_diacritics(name)
    if not name:
        return False

    changed = False

    # 1) Cover table: "Generated by:" (label bên trái)
    for t in doc.tables:
        for r in t.rows:
            cells = r.cells
            for j in range(len(cells) - 1):
                left = (cells[j].text or "").strip()
                if left == "Generated by:":
                    right = cells[j + 1]
                    cur = (right.text or "").strip()
                    if _is_placeholder_dash(cur) or cur == "":
                        _set_cell_text_with_style(right, cells[j], name)
                        changed = True

    # 2) Signature block: tìm hàng header có 'Tested by', 'Generated by', 'Reviewed by'
    for t in doc.tables:
        for i, r in enumerate(t.rows):
            heads_norm = [_norm(c.text) for c in r.cells]
            if "generated by" in heads_norm:
                gen_idx = heads_norm.index("generated by")
                if i + 1 < len(t.rows):
                    cell_below = t.rows[i + 1].cells[gen_idx]
                    cur = (cell_below.text or "").strip()
                    if _is_placeholder_dash(cur) or cur == "":
                        # Giữ style theo cell header tương ứng
                        _set_cell_text_with_style(cell_below, r.cells[gen_idx], name, align_center=True)
                        changed = True
    return changed

def _is_placeholder_dash(txt: str) -> bool:
    if txt is None:
        return True
    t = re.sub(r"[\s\r\n\t]+", "", str(txt or ""))
    return t in BLANK_TOKENS

def _is_result_placeholder(txt: str) -> bool:
    """Chỉ coi là placeholder nếu là '-' hoặc các dạng gạch ngang."""
    if txt is None:
        return True
    s = _norm(txt)
    return s in {"", "-", "—", "–"}

def _norm(s: str) -> str:
    s = unicodedata.normalize("NFD", str(s or ""))
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = s.lower()
    s = s.replace("không", "khong").replace("(không)", "(khong)").replace("(co)", "(có)")
    s = re.sub(r"[^a-z0-9]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def _token_overlap(a: str, b: str) -> float:
    ta = set(_norm(a).split())
    tb = set(_norm(b).split())
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    return inter / max(1, min(len(ta), len(tb)))

def _clone_first_run_style(src_cell):
    try:
        p = src_cell.paragraphs[0]
        if not p.runs:
            return None, None, None, None
        r = p.runs[0]
        return r.font.name, r.font.size, r.font.bold, r.font.italic
    except Exception:
        return None, None, None, None

def _apply_text_with_font(dst_cell, text, fname=None, fsize=None, fbold=None, fitalic=None, align=None, extra_bottom_text=None):
    for p in list(dst_cell.paragraphs):
        if hasattr(p, "clear"):
            try:
                p.clear()
            except Exception:
                pass
    dst_cell.text = ""

    p1 = dst_cell.paragraphs[0] if dst_cell.paragraphs else dst_cell.add_paragraph("")
    run1 = p1.add_run("" if text is None else str(text))
    if fname:   run1.font.name = fname
    if fsize:   run1.font.size = fsize
    if fbold is not None:   run1.font.bold = fbold
    if fitalic is not None: run1.font.italic = fitalic
    if align is not None:   p1.alignment = align
    pf = p1.paragraph_format
    pf.space_before = Pt(0)
    pf.space_after  = Pt(0)

    if extra_bottom_text:
        p2 = dst_cell.add_paragraph("")
        run2 = p2.add_run(str(extra_bottom_text))
        if fname:   run2.font.name = fname
        if fsize:   run2.font.size = fsize
        run2.font.bold = False  # comment không in đậm
        if fitalic is not None: run2.font.italic = fitalic
        if align is not None:   p2.alignment = align
        pf2 = p2.paragraph_format
        pf2.space_before = Pt(0)
        pf2.space_after  = Pt(0)

def _set_cell_text_with_style(dst_cell, src_label_cell, text, align_center=False):
    fname, fsize, fbold, fitalic = _clone_first_run_style(src_label_cell)
    _apply_text_with_font(
        dst_cell,
        text,
        fname, fsize, fbold, fitalic,
        align=WD_ALIGN_PARAGRAPH.CENTER if align_center else None
    )

# ============================ Excel (TRF) ============================

def get_first_empty_report_all_blank(excel_path):
    wb = load_workbook(excel_path, data_only=True)
    ws = wb.active
    report_col = _find_report_col(ws)

    for row in range(2, ws.max_row + 1):
        all_mid_empty = True
        for col in range(3, 25):  # C..X
            is_blank, _ = _normalize_to_check_blank(ws.cell(row=row, column=col).value)
            if not is_blank:
                all_mid_empty = False
                break
        if all_mid_empty:
            report_no = ws.cell(row=row, column=report_col).value
            if report_no is not None and str(report_no).strip():
                wb.close()
                return str(report_no).strip()
    wb.close()
    return None

# ============================ Unicode checkboxes ============================

def _label_regex(label: str) -> re.Pattern:
    cleaned = re.sub(r'[_\.\-]+', ' ', (label or '').strip())
    parts = [p for p in cleaned.split() if p]
    pattern = r'(☐|☑)\s*' + r'\s*'.join(re.escape(p) for p in parts)
    return re.compile(pattern, flags=re.IGNORECASE)

def build_label_value_map(data):
    label_groups = {
        "test_group": [
            "MATERIAL TEST",
            "FINISHING TEST",
            "CONSTRUCTION TEST",
            "TRANSIT TEST",
            "ENVIRONMENTAL TEST",
        ],
        "test_status": ["1ST", "2ND", "3RD", "...TH"],
        "furniture_testing": ["INDOOR", "OUTDOOR"],
        "sample_return": ["YES", "NO"],
    }

    def _eq_relaxed(label: str, value: str, group: str) -> bool:
        L = (label or "").strip().upper()
        V = (value or "").strip().upper()
        if not V:
            return False
        if group == "test_group":
            V2 = V[:-5].strip() if V.endswith(" TEST") else V
            L2 = L[:-5].strip() if L.endswith(" TEST") else L
            return (V == L) or (V2 == L) or (V == L2) or (V2 == L2)
        if group == "test_status" and label == "...TH":
            return V.endswith("TH") and V not in {"1ST", "2ND", "3RD"}
        return V == L

    label_value_map = {}
    for group, labels in label_groups.items():
        value = data.get(group, None)
        if value is None or (isinstance(value, str) and not value.strip()):
            for label in labels:
                label_value_map[label] = False
        else:
            for label in labels:
                label_value_map[label] = _eq_relaxed(label, str(value), group)

    for field in ["sample_description", "item_code", "supplier", "subcon"]:
        val = str(data.get(field, "")).strip().upper()
        label_value_map[f"{field.upper()} N/A"] = (val == "N/A")

    return label_value_map

def tick_unicode_checkbox_by_label(doc: Document, label_value_map):
    compiled = [(_label_regex(label), bool(value)) for label, value in label_value_map.items()]

    def toggle_text(txt: str) -> str:
        if not txt or ('☐' not in txt and '☑' not in txt):
            return txt
        for pat, value in compiled:
            def _repl(m):
                return ('☑' if value else '☐') + m.group(0)[1:]
            txt = pat.sub(_repl, txt)
        return txt

    for p in doc.paragraphs:
        t = p.text
        if ("☐" in t) or ("☑" in t):
            p.text = toggle_text(t)

    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                t = cell.text
                if ("☐" in t) or ("☑" in t):
                    cell.text = toggle_text(t)

# ============================ PDF convert (optional, Windows) ============================

def try_convert_to_pdf(docx_path, pdf_path):
    try:
        import pythoncom
        pythoncom.CoInitialize()
        from docx2pdf import convert
        convert(docx_path, pdf_path)
    except Exception as e:
        import traceback
        print("PDF convert failed:", e)
        traceback.print_exc()

# ============================ Atomic save ============================

def _lock_path_for(report_no: str) -> str:
    return os.path.join(tempfile.gettempdir(), f"tfr_{report_no}.lock")

def _acquire_lock(path: str, timeout=30):
    t0 = time.time()
    fd = None
    while True:
        try:
            fd = os.open(path, os.O_CREAT | os.O_EXCL | os.O_RDWR)
            return fd
        except FileExistsError:
            if time.time() - t0 > timeout:
                try:
                    os.unlink(path)
                except:
                    pass
            time.sleep(0.05)
        except Exception:
            time.sleep(0.05)

def _release_lock(fd, path: str):
    try:
        os.close(fd)
    except:
        pass
    try:
        os.unlink(path)
    except:
        pass

def _atomic_save_docx(doc: Document, out_path: str):
    tmp = f"{out_path}.tmp-{uuid.uuid4().hex}"
    doc.save(tmp)
    os.replace(tmp, out_path)

# ============================ TRF: fill & export ============================

def fill_docx_and_export_pdf(data, fixed_report_no=None):
    # report no
    if fixed_report_no and str(fixed_report_no).strip():
        report_no = str(fixed_report_no).strip()
    else:
        report_no = get_first_empty_report_all_blank(_smart_excel_path(local_main))
        if not report_no:
            raise Exception("No empty report number available in Excel.")

    data = dict(data or {})
    data["report_no"] = report_no
    template_key = (data.get("template_key") or "other")

    doc = Document(WORD_TEMPLATE)

    # basic field mapping
    mapping = {
        "requestor": "requestor",
        "department": "department",
        "requested date": "request_date",
        "lab test report no.": "report_no",
        "sample description": "sample_description",
        "item code": "item_code",
        "quantity": "quantity",
        "supplier": "supplier",
        "subcon": "subcon",
        "test group": "test_group",
        "test status": "test_status",
        "furniture testing": "furniture_testing",
        "estimated completed date": "estimated_completion_date",
    }
    remark = data.get("remark", "")
    remark_written = False

    for table in doc.tables:
        nrows = len(table.rows)
        ncols = len(table.columns)
        for i, row in enumerate(table.rows):
            for j, cell in enumerate(row.cells):
                label = (
                    cell.text.strip().lower()
                    .replace("(mã item)", "")
                    .replace("(mã material)", "")
                    .replace("*", "")
                )
                if not remark_written and ("other tests/instructions" in label or "remark" in label) and remark:
                    if i + 1 < nrows:
                        below_cell = table.rows[i + 1].cells[j]
                        if not (below_cell.text or "").strip():
                            below_cell.text = str(remark)
                            remark_written = True
                            continue
                if ("emp id" in label or "msnv" in label) and data.get("employee_id", ""):
                    if j + 1 < ncols:
                        target_cell = row.cells[j + 1]
                        if not (target_cell.text or "").strip():
                            target_cell.text = str(data["employee_id"])
                            continue
                for map_label, key in mapping.items():
                    if map_label in ["remark", "employee id"]:
                        continue
                    if map_label in label and key in data and str(data[key]).strip() != "":
                        if j + 1 < ncols:
                            target_cell = row.cells[j + 1]
                            if (target_cell.text or "").strip() == "" or "lab test report no." in label:
                                target_cell.text = str(data[key])

    # Tick boxes
    label_value_map = build_label_value_map(data)
    tick_unicode_checkbox_by_label(doc, label_value_map)

    # === NEW: auto fill Summary/Detail (status + comment + photo) for TRF too ===
    _update_exec_summary_results_from_status(doc, report_no, template_key)
    _update_detail_results_and_comments(doc, report_no, template_key)

    # save
    if not os.path.exists(PDF_OUTPUT_FOLDER):
        os.makedirs(PDF_OUTPUT_FOLDER)
    output_docx = os.path.join(PDF_OUTPUT_FOLDER, f"{report_no}.docx")
    output_pdf  = os.path.join(PDF_OUTPUT_FOLDER, f"{report_no}.pdf")

    lock_path = _lock_path_for(report_no)
    fd = _acquire_lock(lock_path, timeout=30)
    try:
        _atomic_save_docx(doc, output_docx)
    finally:
        _release_lock(fd, lock_path)

    try_convert_to_pdf(output_docx, output_pdf)
    return output_docx, output_pdf, report_no


def approve_request_fill_docx_pdf(req):
    fixed = (req.get("report_no") or "").strip()
    if "etd" in req and not req.get("estimated_completion_date"):
        req = dict(req)
        req["estimated_completion_date"] = req.get("etd")

    if fixed:
        out_docx, out_pdf, report_no = fill_docx_and_export_pdf(req, fixed_report_no=fixed)
    else:
        out_docx, out_pdf, report_no = fill_docx_and_export_pdf(req, fixed_report_no=None)

    if os.path.exists(out_pdf):
        return out_pdf, report_no
    return out_docx, report_no

# ======================= SAMPLE PICTURE =======================

def _find_overview_images(report_id: str) -> list[str]:
    roots = []
    images_root = os.path.join(os.getcwd(), "images")
    report_dods_root = os.path.join(os.getcwd(), "report dods")
    if report_id:
        roots.append(os.path.join(images_root, str(report_id)))
        roots.append(os.path.join(report_dods_root, str(report_id)))
    roots.append(report_dods_root)
    roots.append(images_root)

    found = []
    seen = set()
    for root in roots:
        if not os.path.isdir(root):
            continue
        for name in os.listdir(root):
            low = name.lower()
            if any(low.endswith(ext) for ext in _IMG_EXTS) and "overview" in low:
                p = os.path.join(root, name)
                if p not in seen:
                    seen.add(p)
                    found.append(p)
        if found:
            break

    found.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return found

def _find_sample_picture_target_cell(doc: Document):
    for t in doc.tables:
        rows = t.rows
        for i, row in enumerate(rows):
            for j, cell in enumerate(row.cells):
                if "sample picture" in _norm(cell.text):
                    if i + 1 < len(rows):
                        return rows[i + 1].cells[0]
    return None

def _clear_cell_keep_one_paragraph(cell):
    try:
        cell.text = ""
        if not cell.paragraphs:
            cell.add_paragraph("")
        cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
    except Exception:
        pass
def _clear_cell(cell):
    """Xóa toàn bộ nội dung và paragraph trong cell trước khi thêm ảnh."""
    try:
        # Xóa text
        cell.text = ""
        # Xóa luôn paragraph cũ
        while cell.paragraphs:
            p = cell.paragraphs[0]
            p._element.getparent().remove(p._element)
    except Exception:
        pass

def _insert_overview_images_into_sample_picture(doc: Document, report_id: str) -> bool:
    img_paths = _find_overview_images(report_id)
    if not img_paths:
        return False

    target_cell = _find_sample_picture_target_cell(doc)
    if target_cell is None:
        return False

    # gọi hàm mới: xóa hết paragraph trống
    _clear_cell(target_cell)
    target_cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER

    pic_w = Inches(3.5)
    pic_h = Inches(2.5)

    sect = doc.sections[0]
    avail_w = int((sect.page_width - sect.left_margin - sect.right_margin) * 0.97)
    cols = max(1, int(avail_w // pic_w))

    # tạo table con
    inner = target_cell.add_table(rows=0, cols=cols)
    inner.alignment = WD_ALIGN_PARAGRAPH.CENTER
    inner.autofit = False

    for c in inner.columns:
        for cell in c.cells:
            cell.width = pic_w
            cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER

    r = None
    for idx, path in enumerate(img_paths):
        if idx % cols == 0:
            r = inner.add_row()
        c = r.cells[idx % cols]
        _clear_cell(c)
        c.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
        p = c.paragraphs[0] if c.paragraphs else c.add_paragraph("")
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = p.add_run()
        pic = run.add_picture(path)
        pic.width = pic_w
        pic.height = pic_h

    return True

# ======================= STATUS & COMMENT & PHOTO =======================

def _find_status_file(report_id: str) -> str | None:
    def _candidates(root_dir):
        if not os.path.isdir(root_dir):
            return []
        return [
            os.path.join(root_dir, f)
            for f in os.listdir(root_dir)
            if f.lower().startswith("status") and f.lower().endswith(".txt")
        ]

    base_roots = [os.path.join(os.getcwd(), "images"), os.path.join(os.getcwd(), "report dods")]
    pri_roots = []
    if report_id:
        for b in base_roots:
            pri_roots.append(os.path.join(b, str(report_id)))

    cand = []
    for r in (pri_roots + base_roots):
        if os.path.isdir(r):
            cand.extend(_candidates(r))
    if not cand:
        return None
    cand.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return cand[0]

def _find_comment_file(report_id: str) -> str | None:
    def _candidates(root_dir):
        if not os.path.isdir(root_dir):
            return []
        return [
            os.path.join(root_dir, f)
            for f in os.listdir(root_dir)
            if f.lower().startswith("comment") and f.lower().endswith(".txt")
        ]

    base_roots = [os.path.join(os.getcwd(), "images"), os.path.join(os.getcwd(), "report dods")]
    pri_roots = []
    if report_id:
        for b in base_roots:
            pri_roots.append(os.path.join(b, str(report_id)))

    cand = []
    for r in (pri_roots + base_roots):
        if os.path.isdir(r):
            cand.extend(_candidates(r))
    if not cand:
        return None
    cand.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return cand[0]

def _read_status_map(report_id: str) -> dict:
    fp = _find_status_file(report_id)
    out = {}
    if not fp or not os.path.exists(fp):
        return out
    with open(fp, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            # chấp nhận cả muc4.2, muc8.3.3
            m = re.match(r"^\s*(muc[\d\.]+)\s*:\s*([A-Za-z/ ]+)\s*$", line.strip())
            if not m:
                continue
            key = m.group(1).lower()
            val = m.group(2).strip().upper()
            if val == "NA":
                val = "N/A"
            out[key] = val
    return out


def _read_comment_map(report_id: str) -> dict:
    fp = _find_comment_file(report_id)
    out = {}
    if not fp or not os.path.exists(fp):
        return out
    with open(fp, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            # chấp nhận cả muc4.2, muc8.3.3
            m = re.match(r"^\s*(muc[\d\.]+)\s*:\s*(.+?)\s*$", line.strip())
            if not m:
                continue
            key = m.group(1).lower()
            val = m.group(2).strip()
            out[key] = val
    return out

def _read_sample_info(report_id: str) -> tuple[str, str]:
    """
    Đọc Sample Weight & Sample Size từ file comment_<...>.txt
    - Ưu tiên tìm trong thư mục images/{report_id} và report dods/{report_id}
    - Nếu không có, fallback sang thư mục gốc images/ hoặc report dods/
    Trả về (weight, size), chuỗi rỗng nếu không có.
    """
    fp = _find_comment_file(report_id)
    if not fp or not os.path.exists(fp):
        return "", ""

    weight, size = "", ""
    with open(fp, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            low = line.lower()
            if low.startswith("sample weight"):
                weight = line.split(":", 1)[-1].strip()
            elif low.startswith("sample size"):
                size = line.split(":", 1)[-1].strip()
    return weight, size

# --------- Resolve TEST_GROUP_TITLES key from template_key (auto-mapping) ---------

def _resolve_group_key(template_key: str) -> str | None:
    if not template_key:
        return None
    available_keys = list(TEST_GROUP_TITLES.keys())
    lc_to_orig = {k.lower(): k for k in available_keys}
    direct = lc_to_orig.get(template_key.lower())
    if direct:
        return direct

    alias_map = {
        "bed": "giuong",
        "chair_us": "ghe_us",
        "chair_uk": "ghe_eu",
        "table_us": "ban_us",
        "table_uk": "ban_eu",
        "cabinet_us": "tu_us",
        "cabinet_uk": "tu_eu",
        "mirror": "guong",
        "material_indoor_chuyen": "indoor_chuyen",
        "material_indoor_qa": "indoor_thuong",
        "material_indoor_stone": "indoor_stone",
        "material_indoor_metal": "indoor_metal",
        "material_outdoor": "outdoor_finishing",
        "line_test": "line",
        "transit_2c_np": "transit_2c_np",
        "transit_rh_np": "transit_rh_np",
        "transit_181_lt68": "transit_181_lt68",
        "transit_3a": "transit_3a",
        "transit_3b_np": "transit_3b_np",
        "transit_2c_pallet": "transit_2c_pallet",
        "transit_rh_pallet": "transit_rh_pallet",
        "transit_181_gt68": "transit_181_gt68",
        "transit_3b_pallet": "transit_3b_pallet",
        "hot_cold_test": "hot_cold_test",
        "other": "other",
    }
    alias_target = alias_map.get(template_key.lower())
    if alias_target:
        return lc_to_orig.get(alias_target.lower(), alias_target)

    def _score_key(k):
        return _token_overlap(template_key, k) + _token_overlap(template_key.replace("uk", "eu"), k)

    best_key, best_score = None, 0.0
    for k in available_keys:
        sc = _score_key(k)
        if sc > best_score:
            best_key, best_score = k, sc
    return best_key if best_score >= 0.45 else None

def _prep_title_candidates(template_key: str) -> dict:
    """
    Chuẩn bị {muc -> {full, short}}. 
    Bỏ tiền tố 'Mục x:' để so với Description. Không fuzzy nữa.
    """
    resolved = _resolve_group_key(template_key)
    titles_map = TEST_GROUP_TITLES.get(resolved or "", {}) or {}

    cand = {}
    for muc, info in titles_map.items():
        variants = set()
        for k in ("full", "short"):
            v = (info.get(k) or "").strip()
            if not v:
                continue
            # bỏ tiền tố "Mục x:"
            v2 = re.sub(r"^\s*M[ụu]?c\s*\d+(\.\d+)*\s*:\s*", "", v, flags=re.IGNORECASE).strip()
            variants.add(v2)
        cand[muc.lower()] = {_norm(x) for x in variants if x}
    return cand

def _match_muc(desc: str, clause: str, muc_cands: dict) -> str | None:
    """
    So khớp chính xác: Description chuẩn hóa phải khớp với 1 trong các pattern (full/short).
    Không dựa vào Clause, không fuzzy.
    """
    nd = _norm(desc or "")
    for muc, patterns in muc_cands.items():
        if nd in patterns:
            return muc
    return None

# ======================= Table detection (with synonyms) =======================

def _find_exec_summary_table(doc: Document):
    """
    Nhận diện bảng EXECUTIVE SUMMARY với các alias linh hoạt:
      - Cột 1: "Clause" hoặc "Test property"
      - Cột 2: "Description"
      - Cột 3: "Result"
      - Cột 4 (tuỳ chọn): "Comment(s)" / "*Comments"
    """
    clause_aliases = {"clause", "test property"}
    desc_aliases = {"description"}
    result_aliases = {"result"}
    comment_aliases = {"comment", "comments", "*comments"}

    for t in doc.tables:
        for r in t.rows:
            cells = r.cells
            if len(cells) >= 3:
                heads = [_norm(cells[i].text) for i in range(min(len(cells), 4))]
                if (
                    len(heads) > 2
                    and heads[0] in clause_aliases
                    and heads[1] in desc_aliases
                    and heads[2] in result_aliases
                ):
                    return t
    return None


def _find_detail_table(doc: Document):
    """
    Nhận diện bảng chi tiết:
      - Cột 1: "Clause" hoặc "Test property"
      - Cột 2: "Description"
      - Cột 3: "Test Method/Requirement" hoặc "Criteria"
      - Cột 4: "Result"
      - Cột 5 (tuỳ chọn): "Photo reference"
    """
    clause_aliases = {"clause", "test property"}
    desc_aliases = {"description"}
    req_aliases = {"test method requirement", "criteria", "test method", "requirement"}
    result_aliases = {"result"}
    photo_aliases = {"photo reference", "photo"}

    for t in doc.tables:
        for r in t.rows:
            cells = r.cells
            if len(cells) >= 4:
                heads = [_norm(cells[i].text) for i in range(min(len(cells), 5))]
                if (
                    len(heads) > 3
                    and heads[0] in clause_aliases
                    and heads[1] in desc_aliases
                    and heads[2] in req_aliases
                    and heads[3] in result_aliases
                ):
                    return t
    return None

# ======================= Result/Photo style detection =======================

def _detect_result_style(tbl):
    for r in tbl.rows:
        cells = r.cells
        if len(cells) < 3:
            continue
        c = cells[2]
        t = (c.text or "").strip()
        if t and not _is_placeholder_dash(t):
            fname, fsize, fbold, fitalic = _clone_first_run_style(c)
            try:
                align = c.paragraphs[0].alignment or WD_ALIGN_PARAGRAPH.CENTER
            except Exception:
                align = WD_ALIGN_PARAGRAPH.CENTER
            return fname, fsize, fbold, fitalic, align
    return None, None, None, None, WD_ALIGN_PARAGRAPH.CENTER

def _detect_result_style_detail(tbl):
    for r in tbl.rows:
        cells = r.cells
        if len(cells) < 4:
            continue
        c = cells[3]
        t = (c.text or "").strip()
        if t and not _is_placeholder_dash(t):
            fname, fsize, fbold, fitalic = _clone_first_run_style(c)
            try:
                align = c.paragraphs[0].alignment or WD_ALIGN_PARAGRAPH.CENTER
            except Exception:
                align = WD_ALIGN_PARAGRAPH.CENTER
            return fname, fsize, fbold, fitalic, align
    return None, None, None, None, WD_ALIGN_PARAGRAPH.CENTER

def _detect_photo_style_detail(tbl):
    for r in tbl.rows:
        cells = r.cells
        if len(cells) < 5:
            continue
        c = cells[4]
        t = (c.text or "").strip()
        if t and t.upper() not in {"-", "NO PHOTO"}:
            fname, fsize, fbold, fitalic = _clone_first_run_style(c)
            try:
                align = c.paragraphs[0].alignment or WD_ALIGN_PARAGRAPH.CENTER
            except Exception:
                align = WD_ALIGN_PARAGRAPH.CENTER
            return fname, fsize, fbold, fitalic, align
        if (t or "").upper() == "NO PHOTO":
            try:
                align = c.paragraphs[0].alignment or WD_ALIGN_PARAGRAPH.CENTER
            except Exception:
                align = WD_ALIGN_PARAGRAPH.CENTER
            return None, None, None, None, align
    return None, None, None, None, WD_ALIGN_PARAGRAPH.CENTER

# ======================= Fill Summary & Detail =======================

# Regex chuẩn nhận cả "Sec 4", "Sec. 4.3", "sec.4.5"
_SEC_PATTERN = re.compile(r'\bsec\.?\s*([0-9]+(?:\.[0-9]+)*)', re.IGNORECASE)

def _clean_sec(text: str):
    """Trích số section từ text, ví dụ 'Sec. 4.3' → ('4.3','4')"""
    m = _SEC_PATTERN.search(text or "")
    if not m:
        return None, None
    full = m.group(1)
    major = full.split(".", 1)[0]
    return full.strip(), major.strip()

def _is_exec_placeholder(text: str):
    """Cho phép ghi đè nếu Result đang rỗng, '-', 'N/A', 'N/T'"""
    t = (text or "").strip().upper()
    return t in {"", "-", "—", "–", "N/A", "N/T"}

def _find_result_col(table):
    """Tự tìm cột chứa 'Result' (không phụ thuộc index cố định)."""
    header = [c.text.strip().lower() for c in table.rows[0].cells]
    for i, h in enumerate(header):
        if "result" in h:
            return i
    # fallback: cột gần cuối
    return max(1, len(header) - 2)

def _aggregate_results(values):
    vals = [v.strip().upper() for v in values if v.strip()]
    if not vals:
        return None
    if "FAIL" in vals:
        return "FAIL"
    if all(v == "N/A" for v in vals):
        return "N/A"
    return "PASS"

def _update_exec_summary_results_from_status(doc: Document, report_id: str, template_key: str) -> bool:
    """Gom kết quả chi tiết (Sec.x) để điền vào dòng Executive Summary (Sec major)."""
    changed = False
    exec_tbl = _find_exec_summary_table(doc)
    detail_tbl = _find_detail_table(doc)
    if not exec_tbl or not detail_tbl:
        return False
    fname, fsize, fbold, fitalic, align = _detect_result_style(exec_tbl)

    det_prop_idx, det_res_idx = 0, _find_result_col(detail_tbl)
    exec_prop_idx, exec_res_idx = 0, _find_result_col(exec_tbl)

    # --- Gom nhóm theo major Sec ---
    sec_data = {}
    for row in detail_tbl.rows[1:]:
        cells = row.cells
        if len(cells) <= det_res_idx:
            continue
        prop, res = cells[det_prop_idx].text.strip(), cells[det_res_idx].text.strip()
        full, major = _clean_sec(prop)
        if not major:
            continue
        res_norm = res.strip().upper()
        if res_norm in {"", "-", "—", "–"}:
            continue
        sec_data.setdefault(major, []).append(res_norm)

    # --- Cập nhật vào Exec Summary ---
    for row in exec_tbl.rows[1:]:
        cells = row.cells
        if len(cells) <= exec_res_idx:
            continue
        prop = cells[exec_prop_idx].text.strip()
        res_cell = cells[exec_res_idx]
        cur_val = (res_cell.text or "").strip().upper()
        full, major = _clean_sec(prop)
        if not major or not _is_exec_placeholder(cur_val):
            continue
        if major not in sec_data:
            continue
        agg = _aggregate_results(sec_data[major])
        if not agg:
            continue
        _apply_text_with_font(res_cell, agg, fname, fsize, fbold, fitalic, align=align)
        changed = True

    return changed

# --------- Image helpers ---------

def _all_candidate_images(report_id: str):
    roots = []
    images_root = os.path.join(os.getcwd(), "images")
    report_dods_root = os.path.join(os.getcwd(), "report dods")
    if report_id:
        roots.append(os.path.join(images_root, str(report_id)))
        roots.append(os.path.join(report_dods_root, str(report_id)))
    roots.append(report_dods_root)
    roots.append(images_root)

    files = []
    seen = set()
    for root in roots:
        if not os.path.isdir(root):
            continue
        for name in os.listdir(root):
            low = name.lower()
            if any(low.endswith(ext) for ext in _IMG_EXTS):
                p = os.path.join(root, name)
                if p not in seen:
                    seen.add(p)
                    files.append(p)
    files.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return files

def _extract_muc_and_order_from_name(path: str, known_mucs: set[str] | None = None) -> tuple[str | None, int]:
    """
    Parse tên file thành (muc_key, order).
    Ví dụ:
      - ..._muc4.3_1.png  → ('muc4.3', 1)
      - ..._muc8.2.2_3.jpg → ('muc8.2.2', 3)
      - ..._muc5.7.1.jpeg  → nếu 'muc5.7' ∈ known_mucs và 'muc5.7.1' ∉ known_mucs
                              thì hiểu là ('muc5.7', 1)
    """
    base = os.path.basename(path).lower()
    name_noext = re.sub(r"\.[a-z0-9]+$", "", base)

    # Case A: mucX[.Y...][_ - ]order
    m = re.search(r"muc(?P<muc>\d+(?:\.\d+)*)(?:[ _\-]+(?P<ord>\d+))\b", name_noext)
    if m:
        muc = f"muc{m.group('muc')}"
        order = int(m.group('ord'))
        return muc, order

    # Case B: mucA.B.order (không có underscore)
    m2 = re.search(r"muc(?P<parts>\d+(?:\.\d+)+)\b", name_noext)
    if m2:
        parts = m2.group("parts").split(".")
        full_key = "muc" + ".".join(parts)
        muc, order = full_key, 1
        if len(parts) >= 2:
            maybe_parent = "muc" + ".".join(parts[:-1])
            maybe_ord = parts[-1]
            if maybe_ord.isdigit():
                if known_mucs and (maybe_parent in known_mucs) and (full_key not in known_mucs):
                    muc = maybe_parent
                    order = int(maybe_ord)
        return muc, order

    return None, 0

_IMAGE_INDEX_CACHE: dict[tuple[str, tuple[str, ...]], dict[str, list[str]]] = {}

def _index_images_by_muc(report_id: str, known_mucs: set[str]) -> dict[str, list[str]]:
    """
    Lập chỉ mục {muc → [ảnh1, ảnh2,...]} (ảnh đã sort theo order).
    """
    cache_key = (str(report_id), tuple(sorted(known_mucs)))
    if cache_key in _IMAGE_INDEX_CACHE:
        return _IMAGE_INDEX_CACHE[cache_key]

    paths = _all_candidate_images(report_id)
    buckets: dict[str, list[tuple[int, str]]] = {}

    for p in paths:
        muc, order = _extract_muc_and_order_from_name(p, known_mucs)
        if not muc:
            continue
        if muc not in buckets:
            buckets[muc] = []
        buckets[muc].append((order if order > 0 else 1, p))

    out: dict[str, list[str]] = {}
    for muc, items in buckets.items():
        items.sort(key=lambda it: (it[0], os.path.getmtime(it[1])))
        out[muc] = [path for _, path in items]

    _IMAGE_INDEX_CACHE[cache_key] = out
    return out

def _insert_photo_references_stack(cell, image_paths: list[str], fname=None, fsize=None, fbold=None, fitalic=None, align=None):
    cell.text = ""
    cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER

    if not image_paths:
        p = cell.paragraphs[0] if cell.paragraphs else cell.add_paragraph("")
        run = p.add_run("NO PHOTO")
        run.font.bold = False
        if fname:   run.font.name = fname
        if fsize:   run.font.size = fsize
        if fitalic is not None: run.font.italic = fitalic
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER if align is None else align
        pf = p.paragraph_format
        pf.space_before = Pt(0)
        pf.space_after  = Pt(0)
        return

    for idx, path in enumerate(image_paths):
        if idx < len(cell.paragraphs):
            p = cell.paragraphs[idx]
            if hasattr(p, "clear"):
                try:
                    p.clear()
                except Exception:
                    pass
        else:
            p = cell.add_paragraph("")
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER if align is None else align
        run = p.add_run()
        try:
            pic = run.add_picture(path)
            pic.width = Inches(2.0)
            pic.height = Inches(2.0)
        except Exception:
            continue
        pf = p.paragraph_format
        pf.space_before = Pt(0)
        pf.space_after  = Pt(0)

def _update_detail_results_and_comments(doc: Document, report_id: str, template_key: str) -> bool:
    status_map = _read_status_map(report_id)
    if not status_map:
        return False
    comment_map = _read_comment_map(report_id)

    muc_cands = _prep_title_candidates(template_key)
    if not muc_cands:
        return False

    tbl = _find_detail_table(doc)
    if tbl is None:
        return False

    known_mucs = set(status_map.keys()) | set(comment_map.keys())
    img_index = _index_images_by_muc(report_id, known_mucs)

    fname_r, fsize_r, fbold_r, fitalic_r, align_r = _detect_result_style_detail(tbl)
    fname_p, fsize_p, fbold_p, fitalic_p, align_p = _detect_photo_style_detail(tbl)

    changed = False
    for i, r in enumerate(tbl.rows):
        if i == 0:
            continue
        cells = r.cells
        if len(cells) < 5:
            continue

        clause_text = cells[0].text or ""
        desc_text = cells[1].text or ""
        result_cell = cells[3]
        photo_cell  = cells[4]

        muc = _match_muc(desc_text, clause_text, muc_cands)

        # Result
        if muc:
            cur_val = (result_cell.text or "").strip()
            if _is_result_placeholder(cur_val):
                val = status_map.get(muc)
                if val:
                    extra = comment_map.get(muc, None)
                    _apply_text_with_font(
                        result_cell, val,
                        fname_r, fsize_r, fbold_r, fitalic_r,
                        align=align_r, extra_bottom_text=extra
                    )
                    changed = True

        # Photo
        cur_text = (photo_cell.text or "").strip().upper()
        if cur_text != "NO PHOTO" and (_is_result_placeholder(cur_text) or cur_text == ""):
            photos = img_index.get(muc or "", []) if muc else []
            _insert_photo_references_stack(photo_cell, photos, fname_p, fsize_p, fbold_p, fitalic_p, align_p)
            changed = True

        if not muc:
            cur_text2 = (photo_cell.text or "").strip()
            if _is_result_placeholder(cur_text2) or cur_text2 == "":
                _insert_photo_references_stack(photo_cell, [], fname_p, fsize_p, fbold_p, fitalic_p, align_p)
                changed = True

    return changed

# ======================= Cover table (from Excel) =======================

def _find_result_table(doc: Document):
    cover_labels = {
        "Sample Description:", "Item/ Material code:", "Category:", "Collection:",
        "Country of Destination:", "Supplier/ Subcontractor:", "Customer:",
        "Sample Size:", "Sample Weight:", "Tested by:", "Generated by:"
    }
    for t in doc.tables:
        if len(t.columns) >= 4:
            seen = set()
            for r in t.rows:
                for c in r.cells:
                    txt = (c.text or "").strip()
                    if txt in cover_labels:
                        seen.add(txt)
            if len(seen) >= 4:
                return t
    return doc.tables[0] if doc.tables else None

def _set_result_inline_in_paragraph(paragraph, rating_text: str) -> bool:
    """
    Ghi đè giá trị sau 'RESULT:' trong một paragraph (inline), KHÔNG phụ thuộc placeholder.
    Bảo toàn phần 'RESULT:' và style run đầu tiên tối đa có thể.
    """
    if not rating_text or not paragraph.runs:
        return False

    # Ghép toàn bộ text các run để tìm vị trí sau "RESULT:"
    full = "".join(r.text for r in paragraph.runs)
    m = re.search(r"(?i)(RESULT\s*:\s*)", full)
    if not m:
        return False

    prefix = m.group(1)  # "RESULT: " với khoảng trắng nếu có
    head = full[: m.end()]  # phần trước và bao gồm "RESULT: "

    # Ghi đè: đặt run đầu = head + RATING, xoá text ở các run còn lại
    paragraph.runs[0].text = head + str(rating_text).upper()
    for r in paragraph.runs[1:]:
        r.text = ""

    return True

def _set_result_value(doc: Document, rating_text: str) -> bool:
    """
    Đặt giá trị RESULT theo rating_text.
    - Với TABLE: ghi đè ô bên phải dù đang là '-', 'PASS', 'FAIL', 'DATA', 'N/A', ...
    - Với PARAGRAPH inline: luôn ghi đè phần sau 'RESULT:'.
    Trả về True nếu đã thay ở ít nhất một nơi.
    """
    if not rating_text:
        return False
    rating_text = str(rating_text).strip().upper()

    replaced = False

    # 1) Ưu tiên tìm theo TABLE có cột "RESULT:"
    for t in doc.tables:
        for r in t.rows:
            cells = r.cells
            # tìm ô có label "RESULT:" và ô giá trị bên phải
            for j in range(len(cells) - 1):
                left_txt = (cells[j].text or "").strip()
                if re.match(r"(?i)^RESULT\s*:\s*$", left_txt):
                    right_cell = cells[j + 1]
                    # luôn ghi đè (kể cả đang PASS/FAIL/DATA hoặc '-')
                    _set_cell_text_with_style(right_cell, cells[j], rating_text, align_center=True)
                    replaced = True

    if replaced:
        return True

    # 2) Nếu không khớp TABLE, thử ghi theo PARAGRAPH inline "RESULT:"
    for p in doc.paragraphs:
        txt = p.text or ""
        if re.search(r"(?i)RESULT\s*:", txt):
            if _set_result_inline_in_paragraph(p, rating_text):
                replaced = True

    return replaced

def _normalize(s: str) -> str:
    return (s or "").strip().upper()

def _replace_dash_runs(paragraphs, value: str) -> bool:
    """
    Thay trực tiếp các run đang là dấu '-' (kể cả có khoảng trắng/nbsp), để giữ style.
    Trả về True nếu đã thay ít nhất 1 run.
    """
    replaced = False
    for p in paragraphs:
        for run in p.runs:
            # loại bỏ mọi khoảng trắng thường & đặc biệt trước khi so
            t = re.sub(r"[\s\u00A0\u200B]+", "", run.text or "")
            if t in BLANK_TOKENS:
                run.text = str(value)
                replaced = True
    return replaced

def _process_table(tbl, mapping: dict, overwrite_any: bool) -> bool:
    """
    Duyệt một bảng (và các bảng con trong cell) để điền giá trị theo mapping.
    mapping: keys UPPER như 'REPORT NO.', 'RECEIVED DATE', 'REPORT DATE'
    overwrite_any: nếu True thì luôn ghi đè ô phải; nếu False thì chỉ ghi khi ô phải đang là '-'
    """
    changed = False
    for row in tbl.rows:
        cells = row.cells
        n = len(cells)
        for ci, cell in enumerate(cells):
            left_text = _normalize(cell.text)
            for key, val in mapping.items():
                if key in left_text:
                    # chọn ô bên phải ngay cạnh
                    if ci + 1 < n:
                        right = cells[ci + 1]
                        # 1) thử thay trực tiếp run dấu '-' để giữ style
                        replaced = _replace_dash_runs(right.paragraphs, str(val))
                        # 2) fallback: nếu không có run '-' thì tuỳ chọn ghi đè
                        if not replaced:
                            if overwrite_any or _normalize(right.text) in BLANK_TOKENS :
                                right.text = str(val)
                                replaced = True
                        if replaced:
                            changed = True
            # đệ quy các bảng con trong cell (nested tables)
            for inner in cell.tables:
                if _process_table(inner, mapping, overwrite_any):
                    changed = True
    return changed

def _fill_header_fields(doc: Document, data_row: dict, overwrite_any: bool = False) -> bool:
    """
    Điền Report No., Received Date, Report Date vào các bảng lồng nhau trong HEADER.
    - Chỉ ghi đè run dấu '-' để giữ style; fallback ghi thẳng nếu không tìm thấy run '-'.
    - Duyệt cả primary/first/even headers để tránh miss khi template bật tùy chọn khác nhau.
    Trả về True nếu có thay đổi.
    """
    # Lấy dữ liệu
    report_no = str(data_row.get("Report #", "")).strip()

    received_date = data_row.get("Log in date", "")
    if received_date and pd is not None:
        try:
            received_date = pd.to_datetime(received_date).strftime("%b %d, %Y").upper()
        except Exception:
            received_date = str(received_date)
    else:
        received_date = str(received_date)

    report_date = datetime.today().strftime("%b %d, %Y").upper()

    mapping = {
        "REPORT NO.": report_no or "-",
        "RECEIVED DATE": received_date or "-",
        "REPORT DATE": report_date or "-",
    }

    changed = False
    # Duyệt tất cả section headers: primary, first-page, even-page
    for sec in doc.sections:
        for hdr in [sec.header, sec.first_page_header, sec.even_page_header]:
            if hdr is None:
                continue
            for tbl in hdr.tables:
                if _process_table(tbl, mapping, overwrite_any):
                    changed = True
    return changed
# ======================= Excel path resolution =======================

def _smart_excel_path(path_or_name: str) -> str:
    def _is_excel_file(p):
        low = p.lower()
        return os.path.isfile(p) and (low.endswith(".xlsx") or low.endswith(".xls"))

    def _latest_excel_in_dir(d):
        cands = []
        try:
            for name in os.listdir(d):
                fp = os.path.join(d, name)
                if _is_excel_file(fp):
                    cands.append(fp)
        except Exception:
            pass
        if not cands:
            return ""
        cands.sort(key=lambda p: os.path.getmtime(p), reverse=True)
        return cands[0]

    if path_or_name:
        p = str(path_or_name)
        if _is_excel_file(p):
            return p
        if os.path.isdir(p):
            latest = _latest_excel_in_dir(p)
            if latest:
                return latest
        if os.path.isdir(local_main):
            cand = os.path.join(local_main, p)
            if _is_excel_file(cand):
                return cand
            latest = _latest_excel_in_dir(local_main)
            if latest:
                return latest
        if _is_excel_file(local_main):
            return local_main
        raise FileNotFoundError(f"Excel not found: {path_or_name}")
    else:
        if os.path.isdir(local_main):
            latest = _latest_excel_in_dir(local_main)
            if latest:
                return latest
            raise FileNotFoundError(f"No Excel files found in directory: {local_main}")
        if _is_excel_file(local_main):
            return local_main
        raise FileNotFoundError("Excel path is not provided and local_main is not a valid Excel file or directory.")

def _load_excel_df(excel_path_or_name: str):
    if pd is None:
        raise RuntimeError("pandas is not available")
    excel_path = _smart_excel_path(excel_path_or_name)
    if not os.path.exists(excel_path):
        raise FileNotFoundError(f"Excel not found: {excel_path}")
    df = pd.read_excel(excel_path, sheet_name=0)
    df.columns = [str(c).strip() for c in df.columns]
    return df

# ======================= Generic cover fill from Excel =======================

def fill_cover_from_excel_generic(
    template_docx_path: str,
    excel_path_or_name: str,
    report_id: str,
    template_key: str,
    generated_by: str | None = None,   # NEW: nhận người xuất report
) -> BytesIO:
    if not os.path.exists(template_docx_path):
        raise FileNotFoundError(f"Template not found: {template_docx_path}")

    df = _load_excel_df(excel_path_or_name)

    key_col = None
    for name in ["Report #", "Report#", "Report No", "Report no", "Report", "Report_No", "Report_Number"]:
        if name in df.columns:
            key_col = name
            break
    if not key_col:
        for c in df.columns:
            if "report" in c.lower():
                key_col = c
                break
    if not key_col:
        raise KeyError("Missing 'Report #' column (or variants) in Excel.")

    row_df = df.loc[df[key_col].astype(str).str.strip() == str(report_id or "").strip()]
    if row_df.empty:
        raise ValueError(f"Report # not found: {report_id}")
    row = row_df.iloc[0]
    excel_cols = list(df.columns)

    preferred = {
        "Result:": ["rating", "Rating", "RATING"],
        "Sample Description:": ["Item name / Description", "Item name/Description", "Description", "Item name", "Item Description"],
        "Item/ Material code:": ["Item#", "Item #", "Item code", "Item / Material code", "Item/ Material code"],
        "Category:": ["Category / Component name / Position ", "Category", "Component name", "Position"],
        "Collection:": ["Collection"],
        "Country of Destination:": ["Country of destination", "Country of Destination", "Destination"],
        "Supplier/ Subcontractor:": ["QA comment", "QA Comment", "QA comments", "Supplier / Subcontractor ", "Supplier/ Subcontractor", "Supplier", "Subcontractor"],
        "Customer:": ["Customer / Buyer", "Customer", "Buyer"],
        "Generated by:": [
            "Generated by", "generated by", "Prepared by", "prepared by",
            "Created by", "created by", "Operator", "operator",
            "Exported by", "exported by"
        ],
    }

    def _colnorm(x):
        s = unicodedata.normalize("NFD", str(x or "").strip().lower())
        s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
        s = re.sub(r"[^a-z0-9]+", " ", s)
        return re.sub(r"\s+", " ", s).strip()

    def _tokens(x):
        return set(_colnorm(x).split()) if x else set()

    def _overlap_score(label, colname):
        ln = _colnorm(label)
        cn = _colnorm(colname)
        if not ln or not cn:
            return 0.0
        score = 0.0
        if ln == cn:
            score += 5.0
        if ln in cn:
            score += 3.0
        if cn in ln:
            score += 1.0
        lt = _tokens(label)
        ct = _tokens(colname)
        if lt and ct:
            inter = lt & ct
            score += 4.0 * (len(inter) / max(1, len(lt))) + 2.0 * (len(inter) / max(1, len(ct)))
        return score

    def _pick_best_column(excel_columns, label_text: str, preferred_aliases=None) -> str:
        preferred_aliases = preferred_aliases or []
        is_item_code = _colnorm(label_text) in {"item material code", "item code", "item material"}
        blacklist = {"qr code"} if is_item_code else set()

        best_col, best_score = "", -1.0
        for c in excel_columns:
            if _colnorm(c) in blacklist:
                continue
            sc = _overlap_score(label_text, c)
            if c in preferred_aliases:
                sc += 2.0
            if sc > best_score:
                best_col, best_score = c, sc
        return best_col if best_score > 0.8 else ""

    def _val(row, colname: str) -> str:
        if not colname:
            return ""
        try:
            v = row.get(colname, "")
        except Exception:
            v = ""
        if pd is not None and hasattr(pd, "isna") and pd.isna(v):
            return ""
        return str(v).strip()

    doc = Document(template_docx_path)

    col_rating = next((c for c in excel_cols if _colnorm(c) == "rating"), "")
    if col_rating:
        _set_result_value(doc, _val(row, col_rating))

    tbl = _find_result_table(doc)
    if tbl is None:
        raise RuntimeError("Cover/RESULT table not found in template.")

    # Đọc sample info từ comment file
    weight, size = _read_sample_info(report_id)

    for r in tbl.rows:
        cells = r.cells
        if len(cells) >= 2:
            l_label = (cells[0].text or "").strip()
            if l_label.endswith(":"):
                # --- CUSTOM: Sample Weight & Size ---
                label_norm = _norm(re.sub(r"[:\uFF1A]+$", "", l_label))

                if "sample weight" in label_norm:
                    if weight:
                        replaced = _replace_dash_runs(cells[1].paragraphs, weight)
                        if not replaced and _is_placeholder_dash(cells[1].text):
                            _set_cell_text_with_style(cells[1], cells[0], weight)
                    continue

                if "sample size" in label_norm:
                    if size:
                        replaced = _replace_dash_runs(cells[1].paragraphs, size)
                        if not replaced and _is_placeholder_dash(cells[1].text):
                            _set_cell_text_with_style(cells[1], cells[0], size)
                    continue

                # --- Các field khác vẫn lấy từ Excel ---
                cand = _pick_best_column(excel_cols, l_label, preferred_aliases=preferred.get(l_label))
                if cand:
                    cur = (cells[1].text or "").strip()
                    val = _val(row, cand)
                    if "generated by" in _norm(l_label):
                        # Nếu có dạng "19797 - Nguyen Dinh Hoang" thì chỉ lấy phần sau dấu '-'
                        if "-" in val:
                            val = val.split("-", 1)[1].strip()
                        val = remove_diacritics(val)
                        val = remove_diacritics(val)
                    _set_cell_text_with_style(cells[1], cells[0], val)
        if len(cells) >= 4:
            r_label = (cells[2].text or "").strip()
            if r_label.endswith(":"):
                # >>> THÊM KHỐI SAMPLE Ở BÊN PHẢI NGAY ĐÂY <<<
                r_label_norm = _norm(re.sub(r"[:\uFF1A]+$", "", r_label))

                if "sample weight" in r_label_norm:
                    if weight:
                        replaced = _replace_dash_runs(cells[3].paragraphs, weight)
                        if not replaced and _is_placeholder_dash(cells[3].text):
                            _set_cell_text_with_style(cells[3], cells[2], weight)
                    continue  # Đừng rơi xuống Excel mapping

                if "sample size" in r_label_norm:
                    if size:
                        replaced = _replace_dash_runs(cells[3].paragraphs, size)
                        if not replaced and _is_placeholder_dash(cells[3].text):
                            _set_cell_text_with_style(cells[3], cells[2], size)
                    continue  # Đừng rơi xuống Excel mapping

                # --- Các field KHÁC bên phải vẫn lấy từ Excel như cũ ---
                cand = _pick_best_column(excel_cols, r_label, preferred_aliases=preferred.get(r_label))
                if cand:
                    cur = (cells[3].text or "").strip()
                    if _is_placeholder_dash(cur):
                        _set_cell_text_with_style(cells[3], cells[2], _val(row, cand))

    _insert_overview_images_into_sample_picture(doc, report_id)
    _fill_header_fields(doc, row)
    _fill_generated_by_fields(doc, generated_by)

    _update_detail_results_and_comments(doc, report_id, template_key)
    _update_exec_summary_results_from_status(doc, report_id, template_key)

    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# ======================= Wrappers / Entrypoints =======================

def fill_bed_cover_from_excel(template_docx_path: str, excel_path_or_name: str, report_id: str) -> BytesIO:
    return fill_cover_from_excel_generic(
        template_docx_path=template_docx_path,
        excel_path_or_name=excel_path_or_name,
        report_id=report_id,
        template_key="bed",
    )

def create_report_for_type(report_id: str, template_key: str, excel_path_or_name=None) -> BytesIO:
    """
    Locate template by TEMPLATE_MAP[template_key] next to app.py, then fill.
    Excel path is flexible: file or directory (auto-pick latest).
    """
    template_name = TEMPLATE_MAP.get(template_key)
    if not template_name:
        raise KeyError(f"Template not found for key: {template_key}")
    template_path = os.path.join(os.path.dirname(__file__), template_name)
    return fill_cover_from_excel_generic(
        template_docx_path=template_path,
        excel_path_or_name=excel_path_or_name or local_main,
        report_id=report_id,
        template_key=template_key,
    )
# ========================= END OF FILE =========================